{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOB02dh+R0mt9GMwUSAKv60",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BerkAIcelik/hate-speech-detection-system-using-TR-tweets/blob/main/app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcyllGGMUVEV"
      },
      "outputs": [],
      "source": [
        "!pip install flask-ngrok\n",
        "from flask_ngrok import run_with_ngrok\n",
        "!pip install pyngrok\n",
        "from pyngrok import ngrok\n",
        "\n",
        "!ngrok authtoken ###################################\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install zemberek-python"
      ],
      "metadata": {
        "id": "TPvKR5i0YI4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "import numpy as np\n",
        "import re\n",
        "from gensim.models import Word2Vec\n",
        "from zemberek import TurkishMorphology, TurkishSentenceNormalizer\n",
        "from zemberek.tokenization import TurkishTokenizer\n",
        "from xgboost import XGBClassifier\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Flask API baÅŸlat\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Ngrok ile tÃ¼nel aÃ§\n",
        "public_url = ngrok.connect(5000).public_url\n",
        "print(f\"ðŸ”— Flask API'yi aÃ§mak iÃ§in buraya tÄ±kla: {public_url}\")\n",
        "\n",
        "# Modelleri yÃ¼kle\n",
        "word2vec_path = \"/content/word2vec_model.model\"\n",
        "model_path = \"xgboost_combined_word2vec.pkl\"\n",
        "\n",
        "word2vec_model = Word2Vec.load(word2vec_path)  # Word2Vec Modeli\n",
        "model = joblib.load(model_path)  # XGBoost Modeli\n",
        "\n",
        "# Loading Zemberek components\n",
        "morphology = TurkishMorphology.create_with_defaults()\n",
        "spell_checker = TurkishSpellChecker(morphology)\n",
        "tokenizer = TurkishTokenizer.DEFAULT\n",
        "stop_words = set(stopwords.words('turkish'))\n",
        "normalizer = TurkishSentenceNormalizer(morphology)\n",
        "\n",
        "# Tokenizasyon ve stopword temizleme\n",
        "def tokenize_and_clean(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)  # URL temizleme\n",
        "    text = re.sub(r'@\\w+', '', text)  # KullanÄ±cÄ± etiketleri\n",
        "    text = re.sub(r'[0-9]', '', text)  # SayÄ±larÄ± temizleme\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Noktalama temizleme\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    text = normalizer.normalize(text)  # Zemberek ile normalize et\n",
        "    tokens = [token.content for token in tokenizer.tokenize(text)]\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    return tokens\n",
        "\n",
        "# Word2Vec ile vektÃ¶r oluÅŸturma fonksiyonu\n",
        "def get_word_vector(tokens):\n",
        "    vectors = [word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv]\n",
        "    return np.mean(vectors, axis=0) if vectors else np.zeros(300)  # VektÃ¶r yoksa sÄ±fÄ±rlarla doldur\n",
        "\n",
        "# Flask route'larÄ±\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return \"Flask API Ã‡alÄ±ÅŸÄ±yor!\"\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    data = request.get_json()\n",
        "    tweet = data.get(\"tweet\")\n",
        "\n",
        "    if not tweet:\n",
        "        return jsonify({\"error\": \"LÃ¼tfen bir tweet girin\"}), 400\n",
        "\n",
        "    # Veriyi temizle ve tokenize et\n",
        "    tokens = tokenize_and_clean(tweet)\n",
        "    # VektÃ¶r oluÅŸtur\n",
        "    vector = get_word_vector(tokens)\n",
        "\n",
        "    # Tahmin yap\n",
        "    prediction = model.predict([vector])\n",
        "\n",
        "    # Tahmini dÃ¶ndÃ¼r\n",
        "    return jsonify({\"tweet\": tweet, \"prediction\": str(prediction[0])})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(port=5000)\n"
      ],
      "metadata": {
        "id": "rAFVBzLtYUMd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}